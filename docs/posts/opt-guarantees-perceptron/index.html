<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Michael Murray">
<meta name="dcterms.date" content="2024-06-17">

<title>Home - Global optimization guarantees for shallow neural networks via the Perceptron algorithm</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Home</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html" rel="" target="">
 <span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../teaching.html" rel="" target="">
 <span class="menu-text">Teaching</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Global optimization guarantees for shallow neural networks via the Perceptron algorithm</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Neural Networks</div>
                <div class="quarto-category">Optimization</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Michael Murray </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">June 17, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#convergence-of-the-perceptron-algorithm-for-linearly-seperable-data" id="toc-convergence-of-the-perceptron-algorithm-for-linearly-seperable-data" class="nav-link" data-scroll-target="#convergence-of-the-perceptron-algorithm-for-linearly-seperable-data">Convergence of the perceptron algorithm for linearly seperable data</a></li>
  <li><a href="#from-the-perceptron-to-shallow-neural-networks" id="toc-from-the-perceptron-to-shallow-neural-networks" class="nav-link" data-scroll-target="#from-the-perceptron-to-shallow-neural-networks">From the perceptron to shallow neural networks</a>
  <ul class="collapse">
  <li><a href="#training-with-frozen-outer-weights" id="toc-training-with-frozen-outer-weights" class="nav-link" data-scroll-target="#training-with-frozen-outer-weights">Training with frozen outer weights</a></li>
  <li><a href="#training-both-the-inner-and-outer-layers" id="toc-training-both-the-inner-and-outer-layers" class="nav-link" data-scroll-target="#training-both-the-inner-and-outer-layers">Training both the inner and outer layers</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p><em>In this post we will look at how the proof of convergence for the Perceptron algorithm can be used to derive strong training guarantees for a shallow neural network assuming linearly separable data.</em></p>
<div class="hidden">
%%%%% NEW MATH DEFINITIONS %%%%% $$ %
{lemma}{Lemma}
<p>{}[1]{{#1}} </p>
<p>% Figure reference, lower-case. % Figure reference, capital. For start of sentence % Section reference, lower-case. % Section reference, capital. % Reference to two sections. % Reference to three sections. % Reference to an equation, lower-case. % Reference to an equation, upper case % A raw reference to an equation—avoid using if possible % Reference to a chapter, lower-case. % Reference to an equation, upper case. % Reference to a range of chapters % Reference to an algorithm, lower-case. % Reference to an algorithm, upper case. % Reference to a part, lower case % Reference to a part, upper case </p>
<p>% Random variables % rm is already a command, just don’t name any random variables m </p>
<p>% Random vectors </p>
<p>% Elements of random vectors </p>
<p>% Random matrices </p>
<p>% Elements of random matrices </p>
<p>% Vectors </p>
<p>% Elements of vectors </p>
<p>% Matrix </p>
% Tensor
<p>% </p>
<p>% Graph </p>
<p>% Sets % Don’t use a set called E, because this would be the same as our symbol % for expectation. </p>
<p>% Entries of a matrix </p>
% entries of a tensor % Same font as tensor, without wrapper
<p>% The true underlying data generating distribution % The empirical distribution defined by the training set % The model distribution % Stochastic autoencoder distributions </p>
<p>% Laplace distribution</p>
<p>% Wolfram Mathworld says <span class="math inline">\(L^2\)</span> is for function spaces and <span class="math inline">\(\ell^2\)</span> is for vectors % But then they seem to use <span class="math inline">\(L^2\)</span> for vectors throughout the site, and so does % wikipedia. </p>
<p>% See usage in notation.tex. Chosen to match Daphne’s book.</p>
% MM commands % Defined commands
<p>% </p>
<p>% Caligraphic letters $$</p>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>For neural networks deriving training guarantees for reaching global optima is challenging. In another blog post we showed how such guarantees can be achieved by ensuring the network in question is sufficiently wide (this is the NTK approach). However, the typical width requirements are often unrealistic and moreover are designed in order to keep the parameters within some ball of their initialization throughout training and therefore cannot really explain the rich feature learning observed in practice. In this post we remove any width requirements at the price of having to impose significant structure on the target function and data. In particular we consider the problem of learning a binary classifier <span class="math inline">\(f_{\theta}:\mathbb{R}^d \rightarrow \{\pm 1 \}\)</span> on linearly separable data. To this end let <span class="math inline">\((x_i, y_i)_{i \in [n]}\)</span> denote the training data where <span class="math inline">\(x_i \in \mathbb{R}^d\)</span> are the input features and <span class="math inline">\(y_i \in \{ \pm 1\}\)</span> the output labels. If the problem is linearly separable then there exists a <span class="math inline">\(u \in \mathbb{R}^d\)</span> such that <span class="math inline">\(\text{sign}(\langle a, x_i \rangle)= y_i\)</span>, or equivalently <span class="math inline">\(y_i\langle a, x_i \rangle &gt; 0\)</span> for all <span class="math inline">\(i \in [n]\)</span>. We assume the input data is bounded, i.e., <span class="math inline">\(|| x_i || \leq R\)</span> for all <span class="math inline">\(i \in [n]\)</span>. Letting <span class="math inline">\(f(x; \theta)\)</span> denote the map of a shallow neural network our goal is to understand if gradient descent can find parameters <span class="math inline">\(\theta\)</span> such that <span class="math inline">\(sign(f(x_i;\theta))=y_i\)</span> for all <span class="math inline">\(i \in [n]\)</span>. To achieve this we deploy a neat trick based on the Perceptron algorithm which can be seen in <span class="citation" data-cites="brutzkus2018sgd">(<a href="#ref-brutzkus2018sgd" role="doc-biblioref">Brutzkus et al. 2018</a>)</span>. Our presentation will most closely follow that given in <span class="citation" data-cites="karhadkar2024benign">(<a href="#ref-karhadkar2024benign" role="doc-biblioref">Karhadkar et al. 2024</a>)</span>.</p>
</section>
<section id="convergence-of-the-perceptron-algorithm-for-linearly-seperable-data" class="level2">
<h2 class="anchored" data-anchor-id="convergence-of-the-perceptron-algorithm-for-linearly-seperable-data">Convergence of the perceptron algorithm for linearly seperable data</h2>
<p>Before we consider a shallow neural network, let’s first recall the <strong>Perceptron algorithm</strong>.</p>
<ul>
<li><em>Inputs:</em> <span class="math inline">\((x_i, y_i)_{i \in [n]}\)</span></li>
<li><em>Algorithm:</em>
<ul>
<li><em>Initialize</em> <span class="math inline">\(w(0) = 0_d\)</span>, <span class="math inline">\(t = 1\)</span></li>
<li><em>While there exists a</em> <span class="math inline">\(\pi(t) \in [n]\)</span> <em>s.t.</em> <span class="math inline">\(y_{\pi(t)} \langle w(t), x_{\pi(t)} \rangle \leq 0\)</span> <em>do</em>
<ul>
<li><span class="math inline">\(w(t) = w(t-1) + y_{\pi(t)}x_{\pi(t)}\)</span></li>
<li><span class="math inline">\(t = t + 1\)</span></li>
</ul></li>
<li>return <span class="math inline">\(w(t)\)</span></li>
</ul></li>
</ul>
<p>In the above the map <span class="math inline">\(\pi: \mathbb{N}\rightarrow [n]\)</span> selects a point to update at each iteration. Furthermore observe that at each iteration the Perceptron algorithm improves its performance on at least one feature-label pair in the training set as <span class="math inline">\(y_{\pi(t)} \langle w(t), x_{\pi(t)} \rangle = y_{\pi(t)}\langle w(t-1), x_{\pi(t)} \rangle + 1\)</span>.</p>
<p>For linearly separable data it is possible to show the Perceptron algorithm converges to a global minimizer. Recall that linearly separable means there exists a <span class="math inline">\(u \in \mathbb{R}^d\)</span>, <span class="math inline">\(||u ||=1\)</span> such that <span class="math inline">\(y_i \langle x_i, u \rangle &gt;0\)</span> for all <span class="math inline">\(i \in [n]\)</span> (the requirement that <span class="math inline">\(u\)</span> is unit norm is made for convenience as we can always re-scale by dividing by <span class="math inline">\(||u ||\)</span>). As the decision boundary of the linear classifier <span class="math inline">\(u\)</span> is the vector subspace orthogonal to <span class="math inline">\(u\)</span> then the shortest distance from <span class="math inline">\(x_i\)</span> to this decision boundary is simply <span class="math inline">\(|\langle x_i, u \rangle|\)</span>. Let <span class="math display">\[
\gamma(u) := \min_{i \in [n]} |\langle x_i, u \rangle|,
\]</span> denote the <em>margin</em> of the linear classifier <span class="math inline">\(u\)</span>. Without loss of generality we may as well consider the linear classifier with the <em>maximum margin</em>: to this end moving forward we let <span class="math display">\[
\gamma := \max_{||u ||=1} \min_{i \in [n]} |\langle x_i, u \rangle|
\]</span> denote the max margin and <span class="math inline">\(u\)</span> the max margin classifier. For linearly separable data it is possible to show that the Perceptron algorithm terminates after a finite number of steps and successfully classifies all points in the training sample.</p>
<div id="lem-perceptron" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 1 </strong></span>If <span class="math inline">\((x_i, y_i)_{i \in [n]}\)</span> is linearly separable then the Perceptron algorithm terminates after at most <span class="math inline">\(T \leq \frac{R^2}{\gamma^2}\)</span> iterations and <span class="math display">\[ y_i \langle x_{i} , w(T) \rangle &gt; 0 \]</span> for all <span class="math inline">\(i \in [n]\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The key idea of the proof is to show that <span class="math inline">\(| \langle w(t) , u \rangle |^2\)</span> grows faster than <span class="math inline">\(|| w(t) | |^2\)</span>. By the Cauchy-Schwarz (CS) inequality, for any iteration <span class="math inline">\(t \geq 1\)</span> it must hold that</p>
<p><span class="math display">\[
  |\langle w(t), u \rangle|^2 \leq || w(t) ||^2.
\]</span> Therefore, there must exist an iteration <span class="math inline">\(T\)</span> after which no further updates take place: if this was not true this would imply for some sufficiently large iteration that the CS inequality is invalid! To lower bound <span class="math inline">\(| \langle w(t) , u \rangle |^2\)</span> observe <span class="math display">\[
\begin{align*}
  \langle w(t), u \rangle &amp;\geq \langle w(t-1), u \rangle + y_{\pi(t)} \langle x_{\pi(t)} , u \rangle\\
  &amp; \geq \langle w(t-1), u \rangle + \gamma\\
  &amp; \geq \langle w(t-2), u \rangle + 2 \gamma\\
  &amp; \geq t \gamma.
\end{align*}
\]</span> To upper bound <span class="math inline">\(||w(t)||^2\)</span> note <span class="math display">\[
\begin{align*}
  ||w(t)||^2  &amp;=  ||w(t-1) +  y_{\pi(t)}  x_{\pi(t)}||^2 \\
  &amp;= || w(t-1) ||^2 + 2y_{\pi(t)} \langle x_{\pi(t)}, w(t-1) \rangle + ||x_{\pi(t)}||^2\\
  &amp; \leq || w(t-1) ||^2 + ||x_{\pi(t)}||^2\\
  &amp; \leq|| w(t-1) ||^2 + R^2\\
  &amp; \leq || w(t-1) ||^2 +  2R^2\\
  &amp; \leq t R^2.
\end{align*}
\]</span> Let <span class="math inline">\(T\)</span> denote the iteration at which the Perceptron algorithm terminates where <span class="math inline">\(T = \infty\)</span> indicates the Perceptron algorithm never terminates. Then by the CS inequality <span class="math display">\[
T^2 \gamma^2 \leq |\langle w_t, u \rangle|^2 \leq || w_t ||^2 \leq TR^2
\]</span> which is finite! Rearranging then <span class="math inline">\(T\leq \frac{R^2}{\gamma^2}\)</span> as claimed.</p>
</div>
</section>
<section id="from-the-perceptron-to-shallow-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="from-the-perceptron-to-shallow-neural-networks">From the perceptron to shallow neural networks</h2>
<p>Consider now a shallow neural network <span class="math display">\[
f(x;W,v) = v^T \sigma(Wx) = \sum_{j=1}^{2m} v_j \sigma( \langle w_j, x \rangle)
\]</span> where <span class="math inline">\(W \in \mathbb{R}^{2m \times d}\)</span> is the weight matrix of the first layer, <span class="math inline">\(w_j\)</span> is the <span class="math inline">\(j\)</span>th row of <span class="math inline">\(W\)</span>, <span class="math inline">\(v \in \mathbb{R}^{2m}\)</span> is the vector of output weights and <span class="math inline">\(v_j\)</span> is the <span class="math inline">\(j\)</span>th entry of <span class="math inline">\(v\)</span>. We focus on the Leaky-ReLU non-linearity <span class="math inline">\(\sigma(z) = \max \{ \alpha z, z \}\)</span> for some <span class="math inline">\(\alpha \in (0,1)\)</span>. Consider learning the parameters <span class="math inline">\(W\)</span> and <span class="math inline">\(v\)</span> using gradient descent (GD) with the hinge loss (recall the hinge loss is defined as <span class="math inline">\(\ell(z) = \max \{0 , 1 - z \}\)</span>). Using the minimum norm subgradient (as is standard in most automatic differentiation software) at zero we let <span class="math inline">\(\ell'(z) = -1\)</span> for <span class="math inline">\(z &lt; 1\)</span> and is <span class="math inline">\(0\)</span> otherwise, equivalently we can write this as <span class="math inline">\(\ell'(z) = - \mathbb{1}(z&lt;1)\)</span>. Similarly <span class="math inline">\(\sigma'(z) = \alpha\)</span> for <span class="math inline">\(z \leq 0\)</span> and is <span class="math inline">\(1\)</span> otherwise. A straightforward calculation gives <span class="math display">\[
\begin{align*}
&amp;\frac{\partial f}{\partial w_j}(x;W,v) = v_j \sigma'(\langle w_j, x \rangle) x,\\
&amp;\frac{\partial f}{\partial v_j}(x;W,v) =\sigma(\langle w_j, x \rangle).\\
\end{align*}
\]</span> Consider training the network with gradient descent in order to minimize the loss <span class="math inline">\(L(W,v) = \sum_{i=1}^n \ell(y_i f(x_i, W,v))\)</span>: as <span class="math display">\[
\frac{\partial L}{\partial \theta} = \sum_{i \in [n]} \ell'(y_i f(x_i; W, v))y_i \frac{\partial f}{\partial \theta}(x_i;W,v)
\]</span> then the gradient updates for each neuron <span class="math inline">\(j \in [2m]\)</span> are <span class="math display">\[
\begin{align*}
&amp; w_j(t) =  w_j(t-1) + \eta_w \sum_{i =1}^{n} \mathbb{1}[y_i f(x_i; W(t-1), v(t-1))&lt;1]  v_j(t-1) \sigma'(\langle w_j(t-1), x_i \rangle) y_i x_i,\\
&amp; v_j(t) = v_j(t-1) + \eta_v \sum_{i =1}^{n} \mathbb{1}[y_i f(x_i; W(t-1), v(t-1))&lt;1] \sigma(\langle w_j(t-1), x_i \rangle),
\end{align*}
\]</span> where <span class="math inline">\(\eta_w, \eta_v &gt; 0\)</span> are the learning rates for the inner and outer weights respectively. Inspecting these equations we see that shallow networks trained with hinge loss and GD have a similar update rule to the Perceptron algorithm! Inspired by this observation we pursue the idea of comparing the growth rate of <span class="math inline">\(| \langle v_j(t) w_j(t), u \rangle |^2\)</span> versus <span class="math inline">\(|| v_j(t)w_j(t) ||^2\)</span> for each <span class="math inline">\(j \in [2m]\)</span>. In particular, analogous to studying the growth of <span class="math inline">\(\langle w(t), u \rangle\)</span> for the Perceptron algorithm, we instead study <span class="math display">\[
  A(t) = \sum_{j=1}^{2m}\langle v_j(t) w_j(t), u \rangle.
\]</span> Here we use A for alignment and <span class="math inline">\(u\)</span> again denotes the unit norm weights of the max margin linear classifier. Similarly, instead of considering <span class="math inline">\(||w(t)||^2\)</span> we study <span class="math display">\[
  F(t) = || diag(v(t)) W(t) ||_F^2
\]</span> (we use F for Frobenius) where <span class="math inline">\(diag(v(t))\)</span> is a diagonal square matrix with <span class="math inline">\([diag(v(t))]_{jj} = v_j(t)\)</span>. Again by the CS inequality and assuming the data is linearly separable with max margin unit vetor <span class="math inline">\(u\)</span>, then it must hold that <span class="math display">\[
A^2(t) = |\langle vec(diag(v(t)) W(t)), u \otimes 1_{2m} \rangle|^2 \leq F(t) 2m.
\]</span></p>
<p>Therefore, if we can show that <span class="math inline">\(F(t)\)</span> grows slower than <span class="math inline">\(A(t)\)</span> under the outlined gradient update rule there must be a finite iteration after which the update is zero and the parameters no longer change. We will do this by lower bounding <span class="math inline">\(A(t)\)</span> and upper bounding <span class="math inline">\(F(t)\)</span> in terms of the total number of times each point in the training set contributes to the update of the weights at time <span class="math inline">\(t\)</span>, which we denote <span class="math inline">\(U(t) = \sum_{\tau=1}^{t} |\mathcal{F}(\tau)|\)</span>. This is useful as we can bound the number of updates <span class="math inline">\(T\)</span> by considering the setting where only one point contributes to the update at each time step, leading to the bound <span class="math inline">\(T \leq U(t)\)</span>.</p>
<section id="training-with-frozen-outer-weights" class="level3">
<h3 class="anchored" data-anchor-id="training-with-frozen-outer-weights">Training with frozen outer weights</h3>
<p>First we consider a simplified setting where we freeze the outer weights by setting <span class="math inline">\(\eta_v = 0\)</span>: in this setting we are able to prove analogous results to the Perceptron setting.</p>
<div id="lem-network1" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 2 </strong></span>Suppose the training data <span class="math inline">\((x_i, y_i)_{i\in [n]}\)</span> is linearly separable, assume <span class="math inline">\(\eta_v = 0\)</span>, <span class="math inline">\(\eta_w \leq \frac{1}{nR}\)</span>, <span class="math inline">\(v_j(0) = (-1)^j\)</span> and <span class="math inline">\(||w_j(0) || \leq \lambda_w\)</span> for all <span class="math inline">\(j \in [2m]\)</span>. Then gradient descent will terminate after <span class="math display">\[
T &lt; \frac{2 (\lambda_w \alpha \gamma +1)}{ \eta_w \alpha^2 \gamma^2}
\]</span> iterations, at which point the network will have achieved zero training (hinge) loss.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>First we lower bound <span class="math inline">\(A(t)\)</span>. Let <span class="math inline">\(\mathcal{F}(t) = \{ i \in [n] \; : \; y_i f(x_i; \theta(t -1)) &lt; 1\}\)</span> denote the set of training points that do not have zero hinge loss at the previous iterate <span class="math inline">\(t-1\)</span> (alternatively we can view this set as the points that participate in the update of the weights at the current iterate <span class="math inline">\(t\)</span>). For convenience using <span class="math inline">\(\sigma'_{ji}(t) := \sigma'(\langle w_j(t), x_i \rangle)\)</span> then recalling the gradient update rule we have <span class="math display">\[
\begin{align*}
  w_j(t) =  w_j(t-1) + \eta_w \sum_{i \in \mathcal{F}(t)}^{n} (-1)^j \sigma'_{ji}(t-1) y_i x_i.
\end{align*}
\]</span> As <span class="math inline">\(y_i \langle x_i, u \rangle \geq \gamma\)</span> and <span class="math inline">\(\sigma'_{ji}(t) \geq \alpha &gt;0\)</span> then <span class="math display">\[
\begin{align*}
  A(t) &amp;= \sum_{j=1}^{2m} (-1)^j\langle w_j(t), u \rangle \\
  &amp;= A(t-1) + \eta_w \sum_{j=1}^{2m} \sum_{i \in \mathcal{F}(t)}^{n} \sigma'_{ji}(t) y_i \langle x_i, u\rangle \\
  &amp; \geq  A(t-1) + \eta_w \gamma \alpha \sum_{j=1}^{2m} \sum_{i \in \mathcal{F}(t)}^{n} 1\\
  &amp; = A(t-1) + \eta_w \gamma \alpha 2m |\mathcal{F}(t)|\\
  &amp; = A(0) + \eta_w \gamma \alpha 2m \sum_{\tau = 1}^{t} |\mathcal{F}(\tau)|.
\end{align*}
\]</span> Under our assumptions on the initialization scale <span class="math display">\[
\begin{align*}
A(0) &amp;= \sum_{j=1}^{2m} (-1)^j\langle w_j(0), u \rangle\\
&amp; \geq  - \sum_{j=1}^{2m} | \langle w_j(0), u \rangle| \\
&amp; \geq - 2m \lambda_w.
\end{align*}
\]</span> Therefore, defining <span class="math inline">\(U(t) = \sum_{\tau = 1}^{t} |\mathcal{F}(\tau)|\)</span> we have <span class="math display">\[
  A(t) \geq -2m \lambda_w + 2m \eta_w \alpha \gamma U(t).
\]</span> Before proceeding it is worth emphasizing that we need <span class="math inline">\(\alpha&gt;0\)</span> to make this bound non-trivial and increasing in <span class="math inline">\(t\)</span>. To extend this technique to ReLU networks one might instead explore bounding for each neuron <span class="math inline">\(j \in [2m]\)</span> the set <span class="math inline">\(| \mathcal{F}(t) \cap \mathcal{A}_j(t) |\)</span>, where <span class="math inline">\(\mathcal{A}_j(t) = \{i \in [n]: \; \langle w_j(t), x_i \rangle &gt; 0 \}\)</span>.</p>
<p>For the upper bound on <span class="math inline">\(F(t)\)</span> we again plug in the GD update rule, <span class="math display">\[
\begin{align*}
F(t)
&amp;= \sum_{j=1}^{2m} ||w_j(t) ||^2\\
&amp;= \sum_{j=1}^{2m} || w_j(t-1) + \eta_w \sum_{i \in \mathcal{F}(t)}^{n} (-1)^j \sigma'_{ji}(t-1) y_i x_i ||^2\\
&amp;= \sum_{j=1}^{2m}||w_j(t-1) ||^2 + 2\eta_w \sum_{i \in \mathcal{F}(t)}^{n} \sum_{j=1}^{2m}(-1)^j\sigma'_{ji}(t-1)y_i \langle w_j(t-1),  x_i \rangle \\
&amp;+\eta_w^2 \sum_{j =1}^{2m} \sum_{i,k \in \mathcal{F}(t)}^{n}  (-1)^{2j}\sigma'_{ji}(t-1)\sigma'_{ki}(t-1)\langle x_i, x_k \rangle.
\end{align*}
\]</span> The first term in the above is simply <span class="math inline">\(F(t-1)\)</span>. The second term can be simplified by observing that <span class="math inline">\(\sigma(z) = \sigma'(z) z\)</span> for a piecewise linear function <span class="math inline">\(\sigma\)</span>. Therefore <span class="math display">\[
\begin{align*}
  \eta_w \sum_{i \in \mathcal{F}(t)}^{n} \sum_{j=1}^{2m}(-1)^j\sigma'_{ji}(t-1) \langle w_j(t-1),  x_i \rangle &amp;= \eta_w \sum_{i \in \mathcal{F}(t)}^{n} \sum_{j=1}^{2m}(-1)^j\sigma(\langle w_j(t-1),  x_i \rangle)\\
  &amp;= \eta_w \sum_{i \in \mathcal{F}(t)}^{n} y_i f(x_i; W(t-1))\\
  &amp; &lt; \eta_w |\mathcal{F}(t)|,
\end{align*}
\]</span> where the final inequality follows from the fact that <span class="math inline">\(i \in \mathcal{F}(t)\)</span> implies <span class="math inline">\(y_i f(x_i; W(t-1))&lt;1\)</span>. Finally, the third term in the previous bound on <span class="math inline">\(F(t)\)</span> can be simplified using the inequalities <span class="math inline">\(\sigma_{ji}(t-1)\leq 1\)</span>, <span class="math inline">\(||x_i||\leq R\)</span>, <span class="math inline">\(\eta_w\leq1/nR^2\)</span>, <span class="math inline">\(|\mathcal{F}(t)| \leq n\)</span>, which imply <span class="math display">\[
\eta_w^2 \sum_{j =1}^{2m} \sum_{i,k \in \mathcal{F}(t)}^{n}  (-1)^{2j}\sigma'_{ji}(t-1)\sigma'_{ki}(t-1)\langle x_i, x_k \rangle \leq 2m\eta_w^2 R^2 |\mathcal{F}(t)|^2 \leq 2m \eta_w |\mathcal{F}(t)|.
\]</span> Note the bound placed on the step-size means we avoid having to work with <span class="math inline">\(|\mathcal{F}(t)|^2\)</span>. Proceeding, it follows that <span class="math display">\[
\begin{align*}
F(t) &amp;&lt; F(t-1) + (2 + 2m )\eta_w |\mathcal{F}(t)|\\
&amp; \leq F(t-1) + 4m \eta_w |\mathcal{F}(t)|\\
&amp;&lt; F(0) + 4 m\eta_w \sum_{\tau=1}^t |\mathcal{F}(t)|\\
&amp; = F(0) + 4 m\eta_w  U(t)\\
&amp; = \sum_{j=1}^{2m} ||w_j(0)||^2 + 4 m\eta_w U(t)\\
&amp; \leq 2m \lambda_w^2 + 4 m\eta_w U(t).
\end{align*}
\]</span> By the CS inequality and dividing both sides by <span class="math inline">\(4m^2\)</span> then <span class="math display">\[
\frac{A^2(t)}{4m^2} \leq \frac{F(t)}{2m}.
\]</span> Plugging in the bounds for <span class="math inline">\(A(t)\)</span> and <span class="math inline">\(F(t)\)</span>, using <span class="math inline">\(\lambda_w \leq 1\)</span> and rearranging produces the following sequence of inequalities, <span class="math display">\[
\begin{align*}
(\eta_w \alpha \gamma U(t) - \lambda_w)^2 &amp;&lt; \lambda_w^2 + 2 \eta_w U(t)\\
\eta_w^2 \alpha^2 \gamma^2U^2(t) - 2 \lambda_w \eta_w \alpha \gamma U(t) + \lambda_w^2 &amp;&lt; \lambda_w^2 + 2 \eta_w U(t)\\
\eta_w \alpha^2 \gamma^2U^2(t)  &amp;&lt; 2 (\lambda_w \alpha \gamma +1)  U(t) ,\\
U(t) &amp;\leq \frac{2 (\lambda_w \alpha \gamma +1)}{ \eta_w \alpha^2 \gamma^2}.
\end{align*}
\]</span> To conclude, observe if <span class="math inline">\(T\)</span> is the final iterate then <span class="math display">\[
  T = \sum_{\tau = 1}^{T} 1 \leq \sum_{\tau = 1}^{T} |\mathcal{F}(\tau)| = U(T) &lt;\frac{2 (\lambda_w \alpha \gamma +1)}{ \eta_w \alpha^2 \gamma^2}.
\]</span></p>
</div>
<p>A few reflections on this result are as follows.</p>
<ul>
<li><p><strong>Comparing the bound for shallow network with bound for Perceptron:</strong> as a sense check note both bounds have a term proportional to <span class="math inline">\(\gamma^{-2}\)</span> and <span class="math inline">\(R^2\)</span> (observe in the case of the shallow network this is through <span class="math inline">\(\eta_w\)</span>). In addition, for the shallow network we see that a smaller <span class="math inline">\(\alpha\)</span>, i.e., a Leaky ReLU activation closer to ReLU, we get a weaker bound, while at the other end if we chose a linear activation we would get a bound which is very similar! Perhaps the key difference is that through <span class="math inline">\(\eta_w\)</span> the upper bound on the number of iterations of GD scales proportional to <span class="math inline">\(n\)</span> while the bound for the Perceptron has no dependence on <span class="math inline">\(n\)</span>. Given that we use full-batch GD versus single batch SGD for the Perceptron one might expect the bound for the shallow network to be proportional somehow to <span class="math inline">\(1/n\)</span>, however instead the upper bound grows proportional to <span class="math inline">\(n\)</span> for the shallow network! This arises as a result of two artefacts of the proof: first, to bound <span class="math inline">\(T\)</span> in terms of <span class="math inline">\(U(t)\)</span> we use the lower bound <span class="math inline">\(|\mathcal{F}(t)| \geq 1\)</span> for all <span class="math inline">\(t \leq T\)</span>, i.e., we assume only one point is involved in the update of the parameters at each time step when it could be as large as <span class="math inline">\(n\)</span>. Second, we removed a factor of <span class="math inline">\(|\mathcal{F}(t)|\)</span> by using a step-size which is proportional to <span class="math inline">\(1/n\)</span>. It is worth highlighting that the bound for the Perceptron is in terms of the number of non-zero updates as opposed to the number of updates. One could use exactly the same proof to bound the number of <em>non-zero</em> iterations of mini-batch SGD of size <span class="math inline">\(k \in [n]\)</span> say which would only require the <span class="math inline">\(\eta_w\)</span> proportional to <span class="math inline">\(1/k\)</span> and would thereby remove the dependence on <span class="math inline">\(n\)</span>.</p></li>
<li><p><strong>Width of the network does not matter</strong>: the particular choice of <span class="math inline">\(m\)</span> does not actually matter in terms of impacting the upper bound on the number of iterations. This should not perhaps be overly surprising as the target function is linear and could be solved by a single neuron!</p></li>
<li><p><strong>All neurons are treated the same:</strong> the bounds we have written down are derived without having to study the individual dynamics of neurons, or even sub-groups of neurons. Equivalently put, we used the same bound for every neuron and every time step and avoided considering the activation patterns of each neuron on different data points at different time steps. Analysis of activation patterns is in general quite challenging and current works in this regard typically require additional assumptions on the data, such as the input features being nearly orthogonal, see e.g., <span class="citation" data-cites="NEURIPS2023_6e73c39c">(<a href="#ref-NEURIPS2023_6e73c39c" role="doc-biblioref">George et al. 2023</a>)</span>.</p></li>
<li><p><strong>Does not work for ReLU:</strong> we require <span class="math inline">\(\alpha&gt;0\)</span> as otherwise the lower bound we derived for <span class="math inline">\(A(t)\)</span> does not grow with <span class="math inline">\(t\)</span>. This condition means that our results do not cover ReLU. In order to extend to ReLU a similar technique could be deployed if one where to consider instead bounding <span class="math inline">\(|\mathcal{F}(t) \cap \mathcal{A}(t)|\)</span> instead of <span class="math inline">\(|\mathcal{F}(t)|\)</span>. For ReLU networks it is worth highlighting that points which lie in the intersection of each neuron’s inactive halfspace are zeroed by the network and cannot be fitted: this property clearly introduces sub-optimal stationary points! By comparison, Leaky ReLU networks never zero an input unless they are exactly orthogonal to the weight vectors of every neuron, which is a null set.</p></li>
<li><p><strong>Scale of the initialization <span class="math inline">\(\lambda_w\)</span>:</strong> for linearly separable data the scale of the initialization does not impact convergence, however a larger initialization scale increases the upper bound on <span class="math inline">\(U(t)\)</span> which perhaps suggests that it slows down convergence.</p></li>
<li><p><strong>Step-size <span class="math inline">\(\eta_w\)</span>:</strong> the condition <span class="math inline">\(\eta_w \leq 1/nR^2\)</span> simplifies the upper bound on <span class="math inline">\(F(t)\)</span>, in particular without this assumption the upper bound would depend on <span class="math inline">\(\sum_{\tau=1}^{t}|\mathcal{F}(t)|^2\)</span> instead of <span class="math inline">\(U(t)\)</span>. The dependence of <span class="math inline">\(\eta_w\)</span> on <span class="math inline">\(R^2\)</span> is primarily for convenience in simplifying the expressions encountered in the proof and is not necessary. Observing the role of the step-size in the upper bound then, and agreeing with our intuition, the smaller the step size the larger upper bound, which in turn perhaps suggests GD will take longer to converge. If <span class="math inline">\(\eta_w\)</span> is sufficiently large relative to <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\lambda_w\)</span> then the inequality <span class="math inline">\(A(t)^2 \leq 2m F(t)\)</span> can be reduced to the form <span class="math display">\[
\left(\sum_{\tau=1}^{t} |\mathcal{F}(t)| \right)^2 \leq C \sum_{\tau=1}^{t} |\mathcal{F}(t)|^2
\]</span> for some constant <span class="math inline">\(C\)</span> independent of <span class="math inline">\(n\)</span> and <span class="math inline">\(t\)</span>. As the right-hand-side grows linearly with <span class="math inline">\(t\)</span> while the left-hand-side quadratically then there must be some finite <span class="math inline">\(T\)</span> at which the inequality no longer holds. At this point GD must have terminated, despite the large step-size!</p></li>
</ul>
</section>
<section id="training-both-the-inner-and-outer-layers" class="level3">
<h3 class="anchored" data-anchor-id="training-both-the-inner-and-outer-layers">Training both the inner and outer layers</h3>
<p>A natural question one might ask is what happens if you unfreeze the outer layer weights, i.e., <span class="math inline">\(\era_u \geq 0\)</span>? Practically we should expect nothing to change (you can try this experimentally if you like!), however from the perspective of deriving guarantees our job becomes harder. The first challenge is actually deriving bounds for <span class="math inline">\(A(t)\)</span> and <span class="math inline">\(F(t)\)</span> which are non-trivial: generally given bounded data it will be possible to upper bound at least crudely <span class="math inline">\(F(t)\)</span>, however a positive lower bound on <span class="math inline">\(A(t)\)</span> we will shortly observe is trickier. Second, even if we are able to derive upper and lower bounds this technique only works if the lower bound on <span class="math inline">\(A(t)\)</span> grows faster than <span class="math inline">\(F(t)\)</span> with <span class="math inline">\(t\)</span>.</p>
<p>Consider the lower bound on <span class="math inline">\(A(t)\)</span>: for convenience we use the notation <span class="math inline">\(\phi_{ji}(t) = \phi(\langle w_j(t), x_i \rangle)\)</span> where <span class="math inline">\(\phi \in \{\sigma, \sigma' \}\)</span>, from the update rules we derived previously we have the following. <span class="math display">\[
\begin{align*}
A(t+1) &amp;= \sum_{j=1}^{2m}v_j(t+1) \langle w_j(t+1) ,u \rangle\\
&amp; = \sum_{j=1}^{2m} \left( v_j(t) + \eta_v \sum_{i \in \mathcal{F}(t)} \sigma_{ji}(t) \right) \left(\langle w_j(t) + \eta_w \sum_{k \in \mathcal{F}(t)} v_j(t) \sigma_{jk}'(t)y_k x_k  , u \rangle \right)\\
&amp; = \sum_{j=1}^{2m} \left( v_j(t) + \eta_v \sum_{i \in \mathcal{F}(t)} \sigma_{ji}(t) \right) \left(\langle w_j(t), u \rangle + \eta_w \sum_{k \in \mathcal{F}(t)} v_j(t) \sigma_{jk}'(t) y_k \langle x_k ,u \rangle \right)\\
&amp; = \sum_{j=1}^{2m} v_j(t) \langle w_j(t), u \rangle\\
&amp;+ \eta_w \sum_{k \in \mathcal{F}(t)} \sum_{j=1}^{2m}v_j^2(t) \sigma_{jk}'(t) y_k \langle x_k ,u \rangle\\
&amp;+ \eta_v \sum_{i \in \mathcal{F}(t)} \sum_{j=1}^{2m} \sigma_{ji}(t) \langle w_j(t), u \rangle \\
&amp;+ \eta_v \eta_w \sum_{i,k \in \mathcal{F}(t)} \sum_{j=1}^{2m} v_j(t) \sigma_{ji}(t) \sigma_{jk}'(t) y_k \langle x_k ,u \rangle.
\end{align*}
\]</span> The first of the above four terms is simply <span class="math inline">\(A(t)\)</span>, while the second term is positive as <span class="math display">\[
\eta_w \sum_{k \in \mathcal{F}(t)} \sum_{j=1}^{2m}v_j^2(t) \sigma_{jk}'(t) y_k \langle x_k ,u \rangle \geq ||v(t) ||^2 \alpha \gamma.
\]</span> However, bounding the other two terms from below is challenging and requires a more fine-grained understanding of the dynamics of each neuron. Note in the case where the outer weights was frozen we found ourselves in the easy position where we could apply the same bound to each neuron at each time step. In this sense we were actually able to treat all neurons identically as we could uniformly (both in time and neuron index) bound the alignment with <span class="math inline">\(u\)</span> as well as the growth of the norm.</p>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-brutzkus2018sgd" class="csl-entry" role="listitem">
Brutzkus, Alon, Amir Globerson, Eran Malach, and Shai Shalev-Shwartz. 2018. <span>“<span>SGD</span> Learns over-Parameterized Networks That Provably Generalize on Linearly Separable Data.”</span> In <em>International Conference on Learning Representations</em>. <a href="https://openreview.net/forum?id=rJ33wwxRb">https://openreview.net/forum?id=rJ33wwxRb</a>.
</div>
<div id="ref-NEURIPS2023_6e73c39c" class="csl-entry" role="listitem">
George, Erin, Michael Murray, William Swartworth, and Deanna Needell. 2023. <span>“Training Shallow ReLU Networks on Noisy Data Using Hinge Loss: When Do We Overfit and Is It Benign?”</span> In <em>Advances in Neural Information Processing Systems</em>, edited by A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, 36:35139–89. Curran Associates, Inc. <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/6e73c39cc428c7d264d9820319f31e79-Paper-Conference.pdf">https://proceedings.neurips.cc/paper_files/paper/2023/file/6e73c39cc428c7d264d9820319f31e79-Paper-Conference.pdf</a>.
</div>
<div id="ref-karhadkar2024benign" class="csl-entry" role="listitem">
Karhadkar, Kedar, Erin George, Michael Murray, Guido Montúfar, and Deanna Needell. 2024. <span>“Benign Overfitting in Leaky ReLU Networks with Moderate Input Dimension.”</span> <a href="https://arxiv.org/abs/2403.06903">https://arxiv.org/abs/2403.06903</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>