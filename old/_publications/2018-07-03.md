---
title: "Towards an understanding of CNNs: analysing the recovery of activation pathways via Deep Convolutional Sparse Coding"
collection: publications
permalink: /publication/2018-07-03
excerpt: 'Long version of paper published in IEEE 2018 Data Science Workshop Proceedings.'
date: 2018-07-01
venue: 'IEEE 2018 Data Science Workshop Proceedings'
paperurl: 'http://mm5110.github.io/files/papers/DCNNs_analysed_via_DCSC.pdf'
#citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---

[Paper download](http://mm5110.github.io/files/papers/DCNNs_analysed_via_DCSC.pdf)

Deep Convolutional Sparse Coding (D-CSC) is a framework reminiscent of deep convolutional neural nets (DCNN), but by omitting the learning of the dictionaries one can more transparently analyse the role of the activation function and its ability to recover activation paths through the layers. Papyan, Romano, and Elad conducted an analysis of such an architecture, demonstrated the relationship with DCNNs and proved conditions under which a D-CSC is guaranteed to recover activation paths. A technical innovation of their work highlights that one can view the efficacy of the ReLU nonlinear activation function of a DCNN through a new variant of the tensorâ€™s sparsity, referred to as stripe-sparsity.Using this they proved that representations with an activation density proportional to the ambient dimension of the data are recoverable. We extend their uniform guarantees to a modified model and prove that with high probability the true activation is typically possible to recover for a greater density of activations per layer. Our extension follows from incorporating the prior work on one step thresholding by Schnass and Vandergheynst into the appropriately modified architecture of Papyan et al.