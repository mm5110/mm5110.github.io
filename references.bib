@article{lap-revisited,
author = {Chii-Ruey Hwang},
title = {{Laplace's Method Revisited: Weak Convergence of Probability Measures}},
volume = {8},
journal = {The Annals of Probability},
number = {6},
publisher = {Institute of Mathematical Statistics},
pages = {1177 -- 1182},
keywords = {Laplace's method, smooth manifold, weak convergence},
year = {1980},
doi = {10.1214/aop/1176994579},
URL = {https://doi.org/10.1214/aop/1176994579}
}

@inproceedings{
banerjee2023neural,
title={Neural Tangent Kernel at Initialization: Linear Width Suffices},
author={Arindam Banerjee and Pedro Cisneros-Velarde and Libin Zhu and Misha Belkin},
booktitle={The 39th Conference on Uncertainty in Artificial Intelligence},
year={2023},
url={https://openreview.net/forum?id=VJaoe7Rp9tZ}
}

@misc{clark2012instructors,
      title={The Instructor's Guide to Real Induction}, 
      author={Pete L. Clark},
      year={2012},
      eprint={1208.0973},
      archivePrefix={arXiv},
      primaryClass={math.HO}
}


@book{bhatia97,
  added-at = {2013-06-15T01:58:38.000+0200},
  author = {Bhatia, Rajendra},
  biburl = {https://www.bibsonomy.org/bibtex/269934a372db92a018132c5880987691e/ytyoun},
  interhash = {a52e63731d9a0e304c29b795ed54cf94},
  intrahash = {69934a372db92a018132c5880987691e},
  isbn = {0387948465},
  keywords = {courant-fischer eigenvalues linear.algebra majorization matrix textbook},
  publisher = {Springer},
  timestamp = {2017-02-13T08:18:47.000+0100},
  title = {Matrix Analysis},
  volume = 169,
  year = 1997
}

@inproceedings{
du2018gradient,
title={Gradient Descent Provably Optimizes Over-parameterized Neural Networks},
author={Simon S. Du and Xiyu Zhai and Barnabas Poczos and Aarti Singh},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=S1eK3i09YQ},
}

@misc{jacot2020neural,
      title={Neural Tangent Kernel: Convergence and Generalization in Neural Networks}, 
      author={Arthur Jacot and Franck Gabriel and Clément Hongler},
      year={2020},
      eprint={1806.07572},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{oymak2019moderate,
      title={Towards moderate overparameterization: global convergence guarantees for training shallow neural networks}, 
      author={Samet Oymak and Mahdi Soltanolkotabi},
      year={2019},
      eprint={1902.04674},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@inproceedings{
brutzkus2018sgd,
title={{SGD} Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data},
author={Alon Brutzkus and Amir Globerson and Eran Malach and Shai Shalev-Shwartz},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=rJ33wwxRb},
}


@misc{karhadkar2024benign,
      title={Benign overfitting in leaky ReLU networks with moderate input dimension}, 
      author={Kedar Karhadkar and Erin George and Michael Murray and Guido Montúfar and Deanna Needell},
      year={2024},
      eprint={2403.06903},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{NEURIPS2023_6e73c39c,
 author = {George, Erin and Murray, Michael and Swartworth, William and Needell, Deanna},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {35139--35189},
 publisher = {Curran Associates, Inc.},
 title = {Training shallow ReLU networks on noisy data using hinge loss: when do we overfit and is it benign?},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/6e73c39cc428c7d264d9820319f31e79-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}
